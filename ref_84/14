# 논문 #14: *Indoor Pedestrian Positioning Method Based on UWB with a Graph Convolutional Network and Visual Fusion* (Sensors, 2024)

## 1) 기본 정보
- **주제:** UWB **TDOA** 기반 위치에 **GCN**을 적용하고, **Bi-GRU**로 보정한 **비전 좌표**와 **PF(Particle Filter)**로 융합하여 실내 보행자 위치 정확도 향상  
- **환경/셋업:** 7.5×6.0 m 실내 랩; **UWB 스테이션 4개 + 카메라 1대**; 두 가지 보행 경로 실험

**3줄 요약**
1) **UWB 모듈:** 시계열 위치점을 그래프로 구성(시간 인접 노드 연결)해 **GCN**이 이웃 특징을 집계 → Chan–Taylor 대비 **오차 55% 개선**, 단일 UWB 정확도 **<0.72 m**(80% CDF 기준 **<0.67 m**).  
2) **비전 모듈:** **YOLOv7**로 발 위치 픽셀 검출 → 카메라 보정(기본 모델) → **Bi-GRU 잔차 적합**으로 왜곡 보정 → 80% CDF **0.42 m**, 전통 비전법 대비 **71% 개선**.  
3) **융합:** **PF 기반**으로 UWB·비전 좌표 융합(신뢰도 반영, UWB 미가용 시 보간) → 80% 오차 **≤0.24 m**, 최대오차 **0.66 m**. 단일 모듈 대비 **56%/52%** 개선.

**핵심 기여**
- [x] **시공간 그래프 구성(15노드 창)** + **2-Layer GCN(ELU)**로 TDOA 기반 좌표 회귀  
- [x] **Bi-GRU 잔차 보정**으로 카메라 왜곡·연속성 문제 완화  
- [x] **PF 융합 프레임**(가용성 변동·NLOS/멀티패스 대비) 정식화

---

## 2) 입력 데이터 (Input)
- **UWB(TDOA)**: 마스터+슬레이브 3개 기준의 **3개 TDOA** + **앵커 4개의 3D 좌표(12차원)** → **노드당 15차원**  
- **비전**: YOLOv7로 탐지한 발바닥 픽셀좌표 → 카메라 내부/외부 파라미터로 **월드 좌표** 산출 → **Bi-GRU가 잔차를 학습·보정**

**우리 20D 입력과의 매핑**

| 우리 20D 특징 | 본 논문 특징 | 변환/활용 |
|---|---|---|
| DIST/TDOA | TDOA 3개 | 동일 좌표계/시간 정합 후 투입 |
| CIR/SNR/품질 | 명시적 미사용 | **GCN 입력에 품질 채널 추가**(노드 특징 확장) |
| 비전/IMU | 비전(+Bi-GRU) | 우리 IMU와 **PF 예측** 결합 여지 |

- **호환성:** ✅ 높음 (TDOA 중심 + 딥러닝 프런트엔드 + 필터 융합 구조)

---

## 3) 모델 아키텍처
- **UWB-GCN:**  
  - **그래프 구성:** 시간 인접 **15개 위치점**을 노드로, 선형 체인 인접행렬 *A*  
  - **특징행렬:** 각 노드에 **[4앵커 좌표 12 + TDOA 3] = 15D**  
  - **네트워크:** **Ĥ = D̃⁻¹ᐟ²ÂD̃⁻¹ᐟ²**, 두 개의 GCN 층(+ELU) → FC → **ŷ(좌표)**  
- **비전-Booster:** Zhang 보정 **기본좌표 Wz(t)** + **Bi-GRU가 학습한 잔차 Wr(t)** → **W(t)=Wz+Wr**  
- **융합(PF):** 비선형 상태에서 **입자 예측→가중 업데이트(관측: UWB/비전)→리샘플**로 최종 추정  
- **실시간성 보강:** **UWB 미가용 시간**에는 보간/예측으로 관측 시퀀스 유지 뒤, 가용 시 **직접 융합**

**우리 모델과 비교**

| 구성 요소 | 논문(14) | 우리(20D 멀티태스크) | 차이 |
|---|---|---|---|
| UWB 프런트 | **GCN 회귀** | 품질가중+DL/전통 혼합 | GCN에 품질/맵 채널 추가 여지 |
| 비전 보정 | **Bi-GRU 잔차** | (옵션) Deep 보정 | 동일 아이디어로 보정 일체화 가능 |
| 백엔드 | **PF 융합** | EKF/UKF/FG+PF 옵션 | 동형—바로 플러그인 가능 |

---

## 4) 학습/설정
- **UWB-GCN:** MSE 로스, 15-step 윈도우, 앵커 좌표·TDOA 정규화  
- **비전-Bi-GRU:** 입력 **최근 10프레임**(픽셀·기초좌표·잔차), Adam·MSE  
- **PF:** 가중은 관측-추정 **유클리드 거리** 기반 정규화, 효과적인 **Neff** 기준 리샘플

---

## 5) 실험·결과(대표)
- **UWB 단일:** 80% CDF **≈1.54 m(Chan–Taylor)** → **GCN <0.67 m**, 단일 UWB **<0.72 m**, 최대오차 1.27 m로 억제  
- **비전 단일:** 초기 80% **≤1.45 m** → **Bi-GRU 보정 80% ≤0.42 m**, max 0.89 m (**+71%**)  
- **융합(PF):** **80% ≤0.24 m**, **max 0.66 m**, 단일 대비 **UWB −56% / 비전 −52%**

---

## 6) 우리 연구와의 관계
- **유사점:** (i) **신호→딥러닝 보정/회귀 → 확률 필터 융합** 체인, (ii) 시공간 정보 활용  
- **차이점:** 품질 채널(CIR/SNR)·NLOS 스코어·맵 가중은 본 논문에선 제한적  
- **바로 적용 포인트**
  - [x] **GCN 프런트엔드**: 15-step 슬라이딩 윈도우 + **CIR/SNR/맵 가시성**을 **노드 특징**으로 추가  
  - [x] **Bi-GRU 잔차 보정**을 우리 **카메라/비전 좌표 보정 표준 모듈**로 채택  
  - [x] **PF/EKF 혼합**: 상황별로 **PF(비선형·비가우시안)** ↔ **UKF/FG** 스위칭 벤치마크

**벤치마킹 가치**  
- Related Work: ⭐⭐⭐⭐  
- Baseline(딥러닝 전처리+PF 융합): ⭐⭐⭐⭐⭐  
- 구현 참고(그래프 입력 설계·잔차 보정): ⭐⭐⭐⭐⭐

---

## 7) 논문 작성 활용 메모
- **Related Work 문장 초안**  
  > “TDOA 기반 **UWB-GCN**과 **Bi-GRU** 시각 잔차 보정을 **PF**로 융합해, 단일 모듈 대비 **≥50%** 수준으로 오차를 낮추고 **80%≤0.24 m**를 달성했다.”
- **Methodology 차용**  
  1) **GCN 입력 확장**: [앵커좌표, TDOA, **CIR/SNR, NLOS score, 가시성**]  
  2) **비전 잔차 보정**: Bi-GRU → 우리 카메라 보정 파이프라인에 플러그인  
- **Figure/Table 아이디어**  
  - (Fig) **시공간 그래프**(15노드 체인) & **GCN→PF** 파이프라인  
  - (Tbl) Chan–Taylor vs GCN vs Bi-GRU vs PF-Fusion의 **80% CDF / Max** 비교

---

## 8) 참고 포인트(재현용)
- 그래프 구성(노드=시점, 엣지=인접 시점), **입력 15D/노드**  
- Bi-GRU 입력 길이 10, 잔차 보정식 **W=Wz+Wr**  
- 융합 시 UWB 미가용 구간 처리(보간/예측)와 PF 가중·리샘플 규칙

---

## 9) 구현 체크리스트
- [x] **UWB-GCN 모듈**(DataLoader: 15-step 슬라이딩, 표준화)  
- [x] **비전-Bi-GRU 잔차 보정**(카메라 보정 후 보정값 합성)  
- [x] **PF 융합 엔진**(Neff·보간, UWB/비전 동시·비동시 관측 처리)  
- [ ] **품질채널/맵 특성 추가 Ablation**(CIR/SNR/가시성 on/off)  
- **우선순위:** 🟢
